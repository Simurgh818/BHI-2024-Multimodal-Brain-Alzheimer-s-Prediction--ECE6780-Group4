\section{Related Work}
\label{sec:related}
\subsection{Alzheimer's Disease Classification}
There is a growing interest in using machine learning and deep learning approaches for early detection of Alzheimer's Disease (AD, \cite{lin_convolutional_2018}, \cite{grueso_machine_2021}, \cite{borchert_artificial_2021}). The early stage of AD is called Mild Cognitive Impairment (MCI). A review paper by Grueso and Viejo-Sobera found the best performing machine learning method to classify MCI vs. Normal to be a support vector machine (SVM), with a mean accuracy of 75.4\%, and the best performing deep learning model to be a convolutional neural network (CNN), with a mean accuracy of 78.5\% \cite{grueso_machine_2021}. They found that most studies combined MRI and PET images to increase their classification accuracies compared to just using one modality \cite{grueso_machine_2021}\cite{borchert_artificial_2021}.

Researchers have proposed different ways of integrating information and features from MRI and PET. Initially, researchers worked on multi-kernel learning \cite{hinrichs_predictive_2011}, kernel combinations \cite{zhang_multi-modal_2012}, and the Gaussian Process with mixed kernel \cite{young_accurate_2013}. More recently, researchers have developed custom deep neural networks \cite{lu_multimodal_2018}, low-rank dimensionality reduction and orthogonal rotation in a sparse linear regression framework \cite{zhu_low-rank_2019}, kernel-based approaches \cite{gupta_prediction_2019}, latent representational learning \cite{zhou_latent_2019}, a hypergraph-based multi-task feature selection \cite{shao_hypergraph_2020},\cite{zu_label-aligned_2016} a novel sparse regression to fuse imaging data with auxiliary data \cite{shen_heterogeneous_2021}, image fusion \cite{song_effective_2021}, and feature and intermediate-level fusion methods \cite{singh_multi-modal_2023}.

Song et al. \cite{song_effective_2021} proposed a novel image fusion approach to integrate information from MRI and PET scans for improved AD diagnosis. They performed skull-stripping on structural MRI scans to remove non-brain tissue and reduce noise, registered the MRI to a standard brain atlas template, segmented GM tissue from the registered MRI, co-registered the FDG-PET image to the corresponding registered MRI, and extracted the corresponding GM area from the co-registered PET image. This combined information from two images improved AD diagnosis.

\subsection{Alzheimer's Disease Progression}
Cheng et al. \cite{cheng_multimodal_2015} used sparse multimodal manifold-regularized transfer learning for MCI conversion prediction. Their method includes a criterion based on maximum mean discrepancy for eliminating the negative effect of the difference between AD/NC and pMCI/sMCI, and a sparse semi-supervised manifold-regularized least squares classification method. Other researchers have used autoregressive modeling of multimodal biomarkers \cite{minhas_predicting_2018}, and an Extreme Learning Machine (ELM)-based grading method where features extracted from MRI were combined with ELM gradings of MRI, PET, CSF, and genetic data and then fed into a classifier \cite{lin_predicting_2020}.

Further exploring multimodality in Alzheimer's disease research, V. Adarsh et al. introduced a custom kernel to classify different stages of Alzheimer’s disease and MCI using a multimodal approach by combining imaging data with patient clinical data \cite{adarsh_multimodal_2024}. The model was evaluated on the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset using multiple metrics, including AUC, ROC, accuracy, sensitivity, recall, and precision. The integration of LIME and CAM software improved the transparency of the model, enhancing precision, accuracy, and recall.

C. Ellis Wisley et al. \cite{wisely_convolutional_2022}utilized CNN to extract features from retinal images, combining different types of retinal images in a CNN for feature extraction. The model was evaluated on an AUC curve, achieving an AUC of 0.861 on the validation set and 0.841 on the test set, demonstrating potential clinical applications for Alzheimer's disease diagnosis.

\subsection{Modality Contribution}
Based on the literature, it is unclear whether MRI or PET contributes more to classification performance. In two separate studies, one comparing PET to MRI \cite{wisely_convolutional_2022} and one comparing PET/CT to MRI \cite{zhang_petmr_2017}, it was found that separating these modalities provided equal insights into AD classification and progression. However, combining PET and MRI provided new insights as the structural and functional components of the scans were combined, offering enhanced information. 