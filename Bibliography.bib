@article{lin_convolutional_2018,
	title = {Convolutional {Neural} {Networks}-{Based} {MRI} {Image} {Analysis} for the {Alzheimer}’s {Disease} {Prediction} {From} {Mild} {Cognitive} {Impairment}},
	volume = {12},
	issn = {1662-4548},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6231297/},
	doi = {10.3389/fnins.2018.00777},
	abstract = {Mild cognitive impairment (MCI) is the prodromal stage of Alzheimer’s disease (AD). Identifying MCI subjects who are at high risk of converting to AD is crucial for effective treatments. In this study, a deep learning approach based on convolutional neural networks (CNN), is designed to accurately predict MCI-to-AD conversion with magnetic resonance imaging (MRI) data. First, MRI images are prepared with age-correction and other processing. Second, local patches, which are assembled into 2.5 dimensions, are extracted from these images. Then, the patches from AD and normal controls (NC) are used to train a CNN to identify deep learning features of MCI subjects. After that, structural brain image features are mined with FreeSurfer to assist CNN. Finally, both types of features are fed into an extreme learning machine classifier to predict the AD conversion. The proposed approach is validated on the standardized MRI datasets from the Alzheimer’s Disease Neuroimaging Initiative (ADNI) project. This approach achieves an accuracy of 79.9\% and an area under the receiver operating characteristic curve (AUC) of 86.1\% in leave-one-out cross validations. Compared with other state-of-the-art methods, the proposed one outperforms others with higher accuracy and AUC, while keeping a good balance between the sensitivity and specificity. Results demonstrate great potentials of the proposed CNN-based approach for the prediction of MCI-to-AD conversion with solely MRI data. Age correction and assisted structural brain image features can boost the prediction performance of CNN.},
	urldate = {2024-01-28},
	journal = {Front Neurosci},
	author = {Lin, Weiming and Tong, Tong and Gao, Qinquan and Guo, Di and Du, Xiaofeng and Yang, Yonggui and Guo, Gang and Xiao, Min and Du, Min and Qu, Xiaobo},
	month = nov,
	year = {2018},
	pmid = {30455622},
	pmcid = {PMC6231297},
	pages = {777},
	file = {PubMed Central Full Text PDF:C\:\\Users\\sinad\\Zotero\\storage\\9DWIYGYA\\Lin et al. - 2018 - Convolutional Neural Networks-Based MRI Image Anal.pdf:application/pdf},
}

@article{grueso_machine_2021,
	title = {Machine learning methods for predicting progression from mild cognitive impairment to {Alzheimer}’s disease dementia: a systematic review},
	volume = {13},
	issn = {1758-9193},
	shorttitle = {Machine learning methods for predicting progression from mild cognitive impairment to {Alzheimer}’s disease dementia},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8480074/},
	doi = {10.1186/s13195-021-00900-w},
	abstract = {Background
An increase in lifespan in our society is a double-edged sword that entails a growing number of patients with neurocognitive disorders, Alzheimer’s disease being the most prevalent. Advances in medical imaging and computational power enable new methods for the early detection of neurocognitive disorders with the goal of preventing or reducing cognitive decline. Computer-aided image analysis and early detection of changes in cognition is a promising approach for patients with mild cognitive impairment, sometimes a prodromal stage of Alzheimer’s disease dementia.

Methods
We conducted a systematic review following PRISMA guidelines of studies where machine learning was applied to neuroimaging data in order to predict whether patients with mild cognitive impairment might develop Alzheimer’s disease dementia or remain stable. After removing duplicates, we screened 452 studies and selected 116 for qualitative analysis.

Results
Most studies used magnetic resonance image (MRI) and positron emission tomography (PET) data but also magnetoencephalography. The datasets were mainly extracted from the Alzheimer’s disease neuroimaging initiative (ADNI) database with some exceptions. Regarding the algorithms used, the most common was support vector machine with a mean accuracy of 75.4\%, but convolutional neural networks achieved a higher mean accuracy of 78.5\%. Studies combining MRI and PET achieved overall better classification accuracy than studies that only used one neuroimaging technique. In general, the more complex models such as those based on deep learning, combined with multimodal and multidimensional data (neuroimaging, clinical, cognitive, genetic, and behavioral) achieved the best performance.

Conclusions
Although the performance of the different methods still has room for improvement, the results are promising and this methodology has a great potential as a support tool for clinicians and healthcare professionals.},
	urldate = {2024-02-01},
	journal = {Alzheimers Res Ther},
	author = {Grueso, Sergio and Viejo-Sobera, Raquel},
	month = sep,
	year = {2021},
	pmid = {34583745},
	pmcid = {PMC8480074},
	pages = {162},
	file = {PubMed Central Full Text PDF:C\:\\Users\\sinad\\Zotero\\storage\\L7WLEABY\\Grueso and Viejo-Sobera - 2021 - Machine learning methods for predicting progressio.pdf:application/pdf},
}

@misc{who_dementia_nodate,
	title = {Dementia},
	url = {https://www.who.int/news-room/fact-sheets/detail/dementia},
	abstract = {WHO fact sheet on dementia providing key facts and information on signs and symptoms, rates, risk factors, social and economic impacts, human rights, WHO response.},
	language = {en},
	urldate = {2024-03-24},
	author = {WHO},
	file = {Snapshot:C\:\\Users\\sinad\\Zotero\\storage\\AFTVNWTR\\dementia.html:text/html},
}

@misc{borchert_artificial_2021,
	title = {Artificial intelligence for diagnosis and prognosis in neuroimaging for dementia; a systematic review},
	copyright = {© 2021, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at http://creativecommons.org/licenses/by/4.0/},
	url = {https://www.medrxiv.org/content/10.1101/2021.12.12.21267677v1},
	doi = {10.1101/2021.12.12.21267677},
	abstract = {Introduction Recent developments in artificial intelligence (AI) and neuroimaging offer new opportunities for improving diagnosis and prognosis of dementia. To synthesise the available literature, we performed a systematic review.
Methods We systematically reviewed primary research publications up to January 2021, using AI for neuroimaging to predict diagnosis and/or prognosis in cognitive neurodegenerative diseases. After initial screening, data from each study was extracted, including: demographic information, AI methods, neuroimaging features, and results.
Results We found 2709 reports, with 252 eligible papers remaining following screening. Most studies relied on the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset (n=178) with no other individual dataset used more than 5 times. Algorithmic classifiers, such as support vector machine (SVM), were the most commonly used AI method (47\%) followed by discriminative (32\%) and generative (11\%) classifiers. Structural MRI was used in 71\% of studies with a wide range of accuracies for the diagnosis of neurodegenerative diseases and predicting prognosis. Lower accuracy was found in studies using a multi-class classifier or an external cohort as the validation group. There was improvement in accuracy when neuroimaging modalities were combined, e.g. PET and structural MRI. Only 17 papers studied non-Alzheimer’s disease dementias.
Conclusion The use of AI with neuroimaging for diagnosis and prognosis in dementia is a rapidly emerging field. We make a number of recommendations addressing the definition of key clinical questions, heterogeneity of AI methods, and the availability of appropriate and representative data. We anticipate that addressing these issues will enable the field to move towards meaningful clinical translation.},
	language = {en},
	urldate = {2024-03-24},
	publisher = {medRxiv},
	author = {Borchert, R. and Azevedo, T. and Badhwar, A. and Bernal, J. and Betts, M. and Bruffaerts, R. and Burkhart, M. C. and Dewachter, I. and Gellersen, H. M. and Low, A. and Machado, L. and Madan, C. R. and Malpetti, M. and Mejia, J. and Michopoulou, S. and Muñoz-Neira, C. and Peres, M. and Phillips, V. and Ramanan, S. and Tamburin, S. and Tantiangco, H. and Thakur, L. and Tomassini, A. and Vipin, A. and Tang, E. and Newby, D. and Ranson, J. and Llewellyn, D. J. and Veldsman, M. and Rittman, T.},
	month = dec,
	year = {2021},
	note = {ISSN: 2126-7677
Pages: 2021.12.12.21267677},
	file = {Full Text PDF:C\:\\Users\\sinad\\Zotero\\storage\\U4XIZBZC\\Borchert et al. - 2021 - Artificial intelligence for diagnosis and prognosi.pdf:application/pdf},
}

@article{cheng_multimodal_2015,
	title = {Multimodal manifold-regularized transfer learning for {MCI} conversion prediction},
	volume = {9},
	issn = {1931-7557, 1931-7565},
	url = {http://link.springer.com/10.1007/s11682-015-9356-x},
	doi = {10.1007/s11682-015-9356-x},
	language = {en},
	number = {4},
	urldate = {2024-04-04},
	journal = {Brain Imaging and Behavior},
	author = {Cheng, Bo and Liu, Mingxia and Suk, Heung-Il and Shen, Dinggang and Zhang, Daoqiang},
	month = dec,
	year = {2015},
	pages = {913--926},
	file = {Alzheimer’s Disease Neuroimaging Initiative et al. - 2015 - Multimodal manifold-regularized transfer learning .pdf:C\:\\Users\\sinad\\Zotero\\storage\\YMXQK2JU\\Alzheimer’s Disease Neuroimaging Initiative et al. - 2015 - Multimodal manifold-regularized transfer learning .pdf:application/pdf},
}

@article{minhas_predicting_2018,
	title = {Predicting {Progression} {From} {Mild} {Cognitive} {Impairment} to {Alzheimer}'s {Disease} {Using} {Autoregressive} {Modelling} of {Longitudinal} and {Multimodal} {Biomarkers}},
	volume = {22},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {2168-2194, 2168-2208},
	url = {https://ieeexplore.ieee.org/document/7929276/},
	doi = {10.1109/JBHI.2017.2703918},
	language = {en},
	number = {3},
	urldate = {2024-04-06},
	journal = {IEEE J. Biomed. Health Inform.},
	author = {Minhas, Sidra and Khanum, Aasia and Riaz, Farhan and Khan, Shoab A. and Alvi, Atif},
	month = may,
	year = {2018},
	pages = {818--825},
	file = {Minhas et al. - 2018 - Predicting Progression From Mild Cognitive Impairm.pdf:C\:\\Users\\sinad\\Zotero\\storage\\LKLINPLI\\Minhas et al. - 2018 - Predicting Progression From Mild Cognitive Impairm.pdf:application/pdf},
}

@article{zhang_predicting_2012,
	title = {Predicting {Future} {Clinical} {Changes} of {MCI} {Patients} {Using} {Longitudinal} and {Multimodal} {Biomarkers}},
	volume = {7},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0033182},
	doi = {10.1371/journal.pone.0033182},
	abstract = {Accurate prediction of clinical changes of mild cognitive impairment (MCI) patients, including both qualitative change (i.e., conversion to Alzheimer’s disease (AD)) and quantitative change (i.e., cognitive scores) at future time points, is important for early diagnosis of AD and for monitoring the disease progression. In this paper, we propose to predict future clinical changes of MCI patients by using both baseline and longitudinal multimodality data. To do this, we first develop a longitudinal feature selection method to jointly select brain regions across multiple time points for each modality. Specifically, for each time point, we train a sparse linear regression model by using the imaging data and the corresponding clinical scores, with an extra ‘group regularization’ to group the weights corresponding to the same brain region across multiple time points together and to allow for selection of brain regions based on the strength of multiple time points jointly. Then, to further reflect the longitudinal changes on the selected brain regions, we extract a set of longitudinal features from the original baseline and longitudinal data. Finally, we combine all features on the selected brain regions, from different modalities, for prediction by using our previously proposed multi-kernel SVM. We validate our method on 88 ADNI MCI subjects, with both MRI and FDG-PET data and the corresponding clinical scores (i.e., MMSE and ADAS-Cog) at 5 different time points. We first predict the clinical scores (MMSE and ADAS-Cog) at 24-month by using the multimodality data at previous time points, and then predict the conversion of MCI to AD by using the multimodality data at time points which are at least 6-month ahead of the conversion. The results on both sets of experiments show that our proposed method can achieve better performance in predicting future clinical changes of MCI patients than the conventional methods.},
	language = {en},
	number = {3},
	urldate = {2024-04-06},
	journal = {PLoS ONE},
	author = {Zhang, Daoqiang and Shen, Dinggang and {Alzheimer's Disease Neuroimaging Initiative}},
	editor = {Chen, Kewei},
	month = mar,
	year = {2012},
	pages = {e33182},
	file = {Zhang et al. - 2012 - Predicting Future Clinical Changes of MCI Patients.pdf:C\:\\Users\\sinad\\Zotero\\storage\\6E49TAQN\\Zhang et al. - 2012 - Predicting Future Clinical Changes of MCI Patients.pdf:application/pdf},
}

@article{zu_label-aligned_2016,
	title = {Label-aligned multi-task feature learning for multimodal classification of {Alzheimer}’s disease and mild cognitive impairment},
	volume = {10},
	issn = {1931-7557, 1931-7565},
	url = {http://link.springer.com/10.1007/s11682-015-9480-7},
	doi = {10.1007/s11682-015-9480-7},
	language = {en},
	number = {4},
	urldate = {2024-04-06},
	journal = {Brain Imaging and Behavior},
	author = {Zu, Chen and Jie, Biao and Liu, Mingxia and Chen, Songcan and Shen, Dinggang and Zhang, Daoqiang},
	month = dec,
	year = {2016},
	pages = {1148--1159},
	file = {the Alzheimer’s Disease Neuroimaging Initiative et al. - 2016 - Label-aligned multi-task feature learning for mult.pdf:C\:\\Users\\sinad\\Zotero\\storage\\YZY79GJQ\\the Alzheimer’s Disease Neuroimaging Initiative et al. - 2016 - Label-aligned multi-task feature learning for mult.pdf:application/pdf},
}

@article{zhou_latent_2019,
	title = {Latent {Representation} {Learning} for {Alzheimer}’s {Disease} {Diagnosis} {With} {Incomplete} {Multi}-{Modality} {Neuroimaging} and {Genetic} {Data}},
	volume = {38},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	issn = {0278-0062, 1558-254X},
	url = {https://ieeexplore.ieee.org/document/8698846/},
	doi = {10.1109/TMI.2019.2913158},
	language = {en},
	number = {10},
	urldate = {2024-04-06},
	journal = {IEEE Trans. Med. Imaging},
	author = {Zhou, Tao and Liu, Mingxia and Thung, Kim-Han and Shen, Dinggang},
	month = oct,
	year = {2019},
	pages = {2411--2422},
	file = {Zhou et al. - 2019 - Latent Representation Learning for Alzheimer’s Dis.pdf:C\:\\Users\\sinad\\Zotero\\storage\\PSGASVTS\\Zhou et al. - 2019 - Latent Representation Learning for Alzheimer’s Dis.pdf:application/pdf},
}

@article{shen_heterogeneous_2021,
	title = {Heterogeneous data fusion for predicting mild cognitive impairment conversion},
	volume = {66},
	issn = {15662535},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1566253520303584},
	doi = {10.1016/j.inffus.2020.08.023},
	abstract = {In the clinical study of Alzheimer’s Disease (AD) with neuroimaging data, it is challenging to identify the progressive Mild Cognitive Impairment (pMCI) subjects from the stableMCI (sMCI) subjects (i.e., the pMCI/sMCI classification) in an individual level because of small inter-group differences between two groups (i.e., pMCIs and sMCIs) as well as high intra-group variations within each group. Moreover, there are a very limited number of subjects available, which cannot guarantee to find informative and discriminative patterns for achieving high diagnostic accuracy. In this paper, we propose a novel sparse regression method to fuse the auxiliary data into the predictor data for the pMCI/sMCI classification, where the predictor data is structural Magnetic Resonance Imaging (MRI) information of both pMCI and sMCI subjects and the auxiliary data includes the ages of the subjects, the Positron Emission Tomography (PET) information of the predictor data, and the structural MRI information of AD and Normal Controls (NC). Specifically, we incorporate the auxiliary data and the predictor data into a unified framework to jointly achieve the following objectives: i) jointly selecting informative features from both the auxiliary data and the predictor data; ii) robust to outliers from both the auxiliary data and the predictor data; and iii) reducing the aging effect due to the possible cause of brain atrophy induced by both the normal aging and the disease progression. As a result, our proposed method jointly selects the useful features from the auxiliary data and the predictor data by taking into account the influence of outliers and the age of the two kinds of data, i.e., the pMCI and sMCI subjects as well as the AD and NC subjects. We further employ the linear Support Vector Machine (SVM) with the selected features of the predictor data to conduct the pMCI/sMCI classification. Experimental results on the public data of Alzheimer’s Disease Neuroimaging Initiative (ADNI) show the proposed method achieved the best classification performance, compared to the best comparison method, in terms of four evaluation metrics.},
	language = {en},
	urldate = {2024-04-06},
	journal = {Information Fusion},
	author = {Shen, Heng Tao and Zhu, Xiaofeng and Zhang, Zheng and Wang, Shui-Hua and Chen, Yi and Xu, Xing and Shao, Jie},
	month = feb,
	year = {2021},
	pages = {54--63},
	file = {Shen et al. - 2021 - Heterogeneous data fusion for predicting mild cogn.pdf:C\:\\Users\\sinad\\Zotero\\storage\\6MYGA7WS\\Shen et al. - 2021 - Heterogeneous data fusion for predicting mild cogn.pdf:application/pdf},
}

@article{shao_hypergraph_2020,
	title = {Hypergraph based multi-task feature selection for multimodal classification of {Alzheimer}'s disease},
	volume = {80},
	issn = {08956111},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0895611118301435},
	doi = {10.1016/j.compmedimag.2019.101663},
	language = {en},
	urldate = {2024-04-06},
	journal = {Computerized Medical Imaging and Graphics},
	author = {Shao, Wei and Peng, Yao and Zu, Chen and Wang, Mingliang and Zhang, Daoqiang},
	month = mar,
	year = {2020},
	pages = {101663},
	file = {Shao et al. - 2020 - Hypergraph based multi-task feature selection for .pdf:C\:\\Users\\sinad\\Zotero\\storage\\WSGJ5R62\\Shao et al. - 2020 - Hypergraph based multi-task feature selection for .pdf:application/pdf},
}

@inproceedings{singh_multi-modal_2023,
	address = {Istanbul, Turkiye},
	title = {Multi-{Modal} {Deep} {Feature} {Integration} for {Alzheimer}'s {Disease} {Staging}},
	copyright = {https://doi.org/10.15223/policy-029},
	isbn = {9798350337488},
	url = {https://ieeexplore.ieee.org/document/10431906/},
	doi = {10.1109/BIBM58861.2023.10431906},
	abstract = {Alzheimer’s disease (AD) is one of the leading causes of dementia and 7th leading cause of death in the United States. The provisional diagnosis of AD relies on comprehensive examinations, including medical history, neurological and psychiatric examinations, cognitive assessments, and neuroimaging studies. Integrating diverse sets of clinical data, including electronic health records (EHRs), medical imaging, and genomic data, enables a holistic view of AD staging analysis. In this study, we propose an end-to-end deep learning architecture to jointly learn from magnetic resonance imaging (MRI), positron emission tomography (PET), EHRs, and genomics data to classify patients into AD, mild cognitive disorders, and controls. We conduct extensive experiments to explore different feature-level and intermediate-level fusion methods. Our findings suggest intermediate multiplicative fusion achieves the best stage prediction performance on the external validation dataset. Compared with unimodal baselines, we can observe that integrative approaches that leverage all four modalities demonstrate superior performance to baselines reliant solely on one or two modalities. In an age-wise comparison, we observe a unique pattern that all fusion methods exhibited superior performance in the earlier age brackets (50-70 years), with performance diminishing as the age group advanced (70-90 years). The proposed integration framework has the potential to augment our understanding of disease diagnosis and progression by leveraging complementary information from multimodal patient data.},
	language = {en},
	urldate = {2024-04-04},
	booktitle = {2023 {IEEE} {International} {Conference} on {Bioinformatics} and {Biomedicine} ({BIBM})},
	publisher = {IEEE},
	author = {Singh, Amritpal and Shi, Wenqi and Wang, May D.},
	month = dec,
	year = {2023},
	pages = {1--6},
	file = {Singh et al. - 2023 - Multi-Modal Deep Feature Integration for Alzheimer.pdf:C\:\\Users\\sinad\\Zotero\\storage\\P6E63P9N\\Singh et al. - 2023 - Multi-Modal Deep Feature Integration for Alzheimer.pdf:application/pdf},
}

@incollection{hutchison_sparse_2013,
	address = {Cham},
	title = {Sparse {Multimodal} {Manifold}-{Regularized} {Transfer} {Learning} for {MCI} {Conversion} {Prediction}},
	volume = {8184},
	isbn = {978-3-319-02266-6 978-3-319-02267-3},
	url = {http://link.springer.com/10.1007/978-3-319-02267-3_32},
	abstract = {Effective prediction of conversion of mild cognitive impairment (MCI) to Alzheimer's disease (AD) is important for early diagnosis of AD, as well as for evaluating AD risk pre-symptomatically. Different from most traditional methods for MCI conversion prediction, in this paper, we propose a novel sparse multimodal manifold-regularized transfer learning classification (SM2TLC) method, which can simultaneously use other related classification tasks (e.g., AD vs. normal controls (NC) classification) and also the unlabeled data for improving the MCI conversion prediction. Our proposed method includes two key components: (1) a criterion based on the maximum mean discrepancy (MMD) for eliminating the negative effect related to the distribution differences between the auxiliary (i.e., AD/NC) and the target (i.e., MCI converters/MCI non-converters) domains, and (2) a sparse semisupervised manifold-regularized least squares classification method for utilization of unlabeled data. Experimental results on the Alzheimer’s Disease Neuroimaging Initiative (ADNI) database show that the proposed method can significantly improve the classification performance between MCI converters and MCI non-converters, compared with the state-of-the-art methods.},
	language = {en},
	urldate = {2024-04-04},
	booktitle = {Machine {Learning} in {Medical} {Imaging}},
	publisher = {Springer International Publishing},
	author = {Cheng, Bo and Zhang, Daoqiang and Jie, Biao and Shen, Dinggang},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Wu, Guorong and Zhang, Daoqiang and Shen, Dinggang and Yan, Pingkun and Suzuki, Kenji and Wang, Fei},
	year = {2013},
	doi = {10.1007/978-3-319-02267-3_32},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {251--259},
	file = {Cheng et al. - 2013 - Sparse Multimodal Manifold-Regularized Transfer Le.pdf:C\:\\Users\\sinad\\Zotero\\storage\\VVQZZZW3\\Cheng et al. - 2013 - Sparse Multimodal Manifold-Regularized Transfer Le.pdf:application/pdf},
}

@article{zhang_multi-modal_2012,
	title = {Multi-modal multi-task learning for joint prediction of multiple regression and classification variables in {Alzheimer}'s disease},
	volume = {59},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S105381191101144X},
	doi = {10.1016/j.neuroimage.2011.09.069},
	abstract = {Many machine learning and pattern classification methods have been applied to the diagnosis of Alzheimer’s disease (AD) and its prodromal stage, i.e., mild cognitive impairment (MCI). Recently, rather than predicting categorical variables as in classification, several pattern regression methods have also been used to estimate continuous clinical variables from brain images. However, most existing regression methods focus on estimating multiple clinical variables separately and thus cannot utilize the intrinsic useful correlation information among different clinical variables. On the other hand, in those regression methods, only a single modality of data (usually only the structural MRI) is often used, without considering the complementary information that can be provided by different modalities. In this paper, we propose a general methodology, namely Multi-Modal Multi-Task (M3T) learning, to jointly predict multiple variables from multi-modal data. Here, the variables include not only the clinical variables used for regression but also the categorical variable used for classification, with different tasks corresponding to prediction of different variables. Specifically, our method contains two key components, i.e., (1) a multi-task feature selection which selects the common subset of relevant features for multiple variables from each modality, and (2) a multi-modal support vector machine which fuses the above-selected features from all modalities to predict multiple (regression and classification) variables. To validate our method, we perform two sets of experiments on ADNI baseline MRI, FDG-PET, and cerebrospinal fluid (CSF) data from 45 AD patients, 91 MCI patients, and 50 healthy controls (HC). In the first set of experiments, we estimate two clinical variables such as Mini Mental State Examination (MMSE) and Alzheimer’s Disease Assessment Scale - Cognitive Subscale (ADAS-Cog), as well as one categorical variable (with value of ‘AD’, ‘MCI’ or ‘HC’), from the baseline MRI, FDG-PET, and CSF data. In the second set of experiments, we predict the 2-year changes of MMSE and ADAS-Cog scores and also the conversion of MCI to AD from the baseline MRI, FDG-PET, and CSF data. The results on both sets of experiments demonstrate that our proposed M3T learning scheme can achieve better performance on both regression and classification tasks than the conventional learning methods.},
	language = {en},
	number = {2},
	urldate = {2024-04-04},
	journal = {NeuroImage},
	author = {Zhang, Daoqiang and Shen, Dinggang},
	month = jan,
	year = {2012},
	pages = {895--907},
	file = {Zhang and Shen - 2012 - Multi-modal multi-task learning for joint predicti.pdf:C\:\\Users\\sinad\\Zotero\\storage\\T6HMP2KG\\Zhang and Shen - 2012 - Multi-modal multi-task learning for joint predicti.pdf:application/pdf},
}

@article{hinrichs_predictive_2011,
	title = {Predictive markers for {AD} in a multi-modality framework: {An} analysis of {MCI} progression in the {ADNI} population},
	volume = {55},
	issn = {10538119},
	shorttitle = {Predictive markers for {AD} in a multi-modality framework},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1053811910015806},
	doi = {10.1016/j.neuroimage.2010.10.081},
	abstract = {Alzheimer's Disease (AD) and other neurodegenerative diseases affect over 20 million people worldwide, and this number is projected to signiﬁcantly increase in the coming decades. Proposed imaging-based markers have shown steadily improving levels of sensitivity/speciﬁcity in classifying individual subjects as AD or normal. Several of these efforts have utilized statistical machine learning techniques, using brain images as input, as means of deriving such AD-related markers. A common characteristic of this line of research is a focus on either (1) using a single imaging modality for classiﬁcation, or (2) incorporating several modalities, but reporting separate results for each. One strategy to improve on the success of these methods is to leverage all available imaging modalities together in a single automated learning framework. The rationale is that some subjects may show signs of pathology in one modality but not in another—by combining all available images a clearer view of the progression of disease pathology will emerge. Our method is based on the Multi-Kernel Learning (MKL) framework, which allows the inclusion of an arbitrary number of views of the data in a maximum margin, kernel learning framework. The principal innovation behind MKL is that it learns an optimal combination of kernel (similarity) matrices while simultaneously training a classiﬁer. In classiﬁcation experiments MKL outperformed an SVM trained on all available features by 3\%–4\%. We are especially interested in whether such markers are capable of identifying early signs of the disease. To address this question, we have examined whether our multi-modal disease marker (MMDM) can predict conversion from Mild Cognitive Impairment (MCI) to AD. Our experiments reveal that this measure shows signiﬁcant group differences between MCI subjects who progressed to AD, and those who remained stable for 3 years. These differences were most signiﬁcant in MMDMs based on imaging data. We also discuss the relationship between our MMDM and an individual's conversion from MCI to AD.},
	language = {en},
	number = {2},
	urldate = {2024-04-04},
	journal = {NeuroImage},
	author = {Hinrichs, Chris and Singh, Vikas and Xu, Guofan and Johnson, Sterling C.},
	month = mar,
	year = {2011},
	pages = {574--589},
	file = {Hinrichs et al. - 2011 - Predictive markers for AD in a multi-modality fram.pdf:C\:\\Users\\sinad\\Zotero\\storage\\4GZLUTK5\\Hinrichs et al. - 2011 - Predictive markers for AD in a multi-modality fram.pdf:application/pdf},
}

@article{song_effective_2021,
	title = {An {Effective} {Multimodal} {Image} {Fusion} {Method} {Using} {MRI} and {PET} for {Alzheimer}'s {Disease} {Diagnosis}},
	volume = {3},
	issn = {2673-253X},
	url = {https://www.frontiersin.org/articles/10.3389/fdgth.2021.637386/full},
	doi = {10.3389/fdgth.2021.637386},
	abstract = {Alzheimer's disease (AD) is an irreversible brain disease that severely damages human thinking and memory. Early diagnosis plays an important part in the prevention and treatment of AD. Neuroimaging-based computer-aided diagnosis (CAD) has shown that deep learning methods using multimodal images are beneficial to guide AD detection. In recent years, many methods based on multimodal feature learning have been proposed to extract and fuse latent representation information from different neuroimaging modalities including magnetic resonance imaging (MRI) and 18-fluorodeoxyglucose positron emission tomography (FDG-PET). However, these methods lack the interpretability required to clearly explain the specific meaning of the extracted information. To make the multimodal fusion process more persuasive, we propose an image fusion method to aid AD diagnosis. Specifically, we fuse the gray matter (GM) tissue area of brain MRI and FDG-PET images by registration and mask coding to obtain a new fused modality called “GM-PET.” The resulting single composite image emphasizes the GM area that is critical for AD diagnosis, while retaining both the contour and metabolic characteristics of the subject's brain tissue. In addition, we use the three-dimensional simple convolutional neural network (3D Simple CNN) and 3D Multi-Scale CNN to evaluate the effectiveness of our image fusion method in binary classification and multi-classification tasks. Experiments on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset indicate that the proposed image fusion method achieves better overall performance than unimodal and feature fusion methods, and that it outperforms state-of-the-art methods for AD diagnosis.},
	language = {en},
	urldate = {2024-04-04},
	journal = {Front. Digit. Health},
	author = {Song, Juan and Zheng, Jian and Li, Ping and Lu, Xiaoyuan and Zhu, Guangming and Shen, Peiyi},
	month = feb,
	year = {2021},
	pages = {637386},
	file = {Song et al. - 2021 - An Effective Multimodal Image Fusion Method Using .pdf:C\:\\Users\\sinad\\Zotero\\storage\\C8CIGVWY\\Song et al. - 2021 - An Effective Multimodal Image Fusion Method Using .pdf:application/pdf},
}

@article{lin_predicting_2020,
	title = {Predicting {Alzheimer}’s {Disease} {Conversion} {From} {Mild} {Cognitive} {Impairment} {Using} an {Extreme} {Learning} {Machine}-{Based} {Grading} {Method} {With} {Multimodal} {Data}},
	volume = {12},
	issn = {1663-4365},
	url = {https://www.frontiersin.org/article/10.3389/fnagi.2020.00077/full},
	doi = {10.3389/fnagi.2020.00077},
	language = {en},
	urldate = {2024-04-04},
	journal = {Front. Aging Neurosci.},
	author = {Lin, Weiming and Gao, Qinquan and Yuan, Jiangnan and Chen, Zhiying and Feng, Chenwei and Chen, Weisheng and Du, Min and Tong, Tong},
	month = apr,
	year = {2020},
	pages = {77},
	file = {Lin et al. - 2020 - Predicting Alzheimer’s Disease Conversion From Mil.pdf:C\:\\Users\\sinad\\Zotero\\storage\\A8ZUUA24\\Lin et al. - 2020 - Predicting Alzheimer’s Disease Conversion From Mil.pdf:application/pdf},
}

@article{gupta_prediction_2019,
	title = {Prediction and {Classification} of {Alzheimer}’s {Disease} {Based} on {Combined} {Features} {From} {Apolipoprotein}-{E} {Genotype}, {Cerebrospinal} {Fluid}, {MR}, and {FDG}-{PET} {Imaging} {Biomarkers}},
	volume = {13},
	issn = {1662-5188},
	url = {https://www.frontiersin.org/article/10.3389/fncom.2019.00072/full},
	doi = {10.3389/fncom.2019.00072},
	language = {en},
	urldate = {2024-04-04},
	journal = {Front. Comput. Neurosci.},
	author = {Gupta, Yubraj and Lama, Ramesh Kumar and Kwon, Goo-Rak and {Alzheimer's Disease Neuroimaging Initiative}},
	month = oct,
	year = {2019},
	pages = {72},
	file = {Gupta et al. - 2019 - Prediction and Classification of Alzheimer’s Disea.pdf:C\:\\Users\\sinad\\Zotero\\storage\\XPZZQ8M5\\Gupta et al. - 2019 - Prediction and Classification of Alzheimer’s Disea.pdf:application/pdf},
}

@article{zhu_low-rank_2019,
	title = {Low-rank dimensionality reduction for multi-modality neurodegenerative disease identification},
	volume = {22},
	issn = {1386-145X, 1573-1413},
	url = {http://link.springer.com/10.1007/s11280-018-0645-3},
	doi = {10.1007/s11280-018-0645-3},
	abstract = {In this paper, we propose a novel dimensionality reduction method of taking the advantages of the variability, sparsity, and low-rankness of neuroimaging data for Alzheimer’s Disease (AD) classification. We first take the variability of neuroimaging data into account by partitioning them into sub-classes by means of clustering, which thus captures the underlying multi-peak distributional characteristics in neuroimaging data. We then iteratively conduct Low-Rank Dimensionality Reduction (LRDR) and orthogonal rotation in a sparse linear regression framework, in order to find the low-dimensional structure of highdimensional data. Experimental results on the Alzheimer’s Disease Neuroimaging Initiative (ADNI) dataset showed that our proposed model helped enhance the performances of AD classification, outperforming the state-of-the-art methods.},
	language = {en},
	number = {2},
	urldate = {2024-04-04},
	journal = {World Wide Web},
	author = {Zhu, Xiaofeng and Suk, Heung-Il and Shen, Dinggang},
	month = mar,
	year = {2019},
	pages = {907--925},
	file = {Zhu et al. - 2019 - Low-rank dimensionality reduction for multi-modali.pdf:C\:\\Users\\sinad\\Zotero\\storage\\3RKSPS59\\Zhu et al. - 2019 - Low-rank dimensionality reduction for multi-modali.pdf:application/pdf},
}

@article{lu_multimodal_2018,
	title = {Multimodal and {Multiscale} {Deep} {Neural} {Networks} for the {Early} {Diagnosis} of {Alzheimer}’s {Disease} using structural {MR} and {FDG}-{PET} images},
	volume = {8},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-018-22871-z},
	doi = {10.1038/s41598-018-22871-z},
	abstract = {Abstract
            Alzheimer’s Disease (AD) is a progressive neurodegenerative disease where biomarkers for disease based on pathophysiology may be able to provide objective measures for disease diagnosis and staging. Neuroimaging scans acquired from MRI and metabolism images obtained by FDG-PET provide in-vivo measurements of structure and function (glucose metabolism) in a living brain. It is hypothesized that combining multiple different image modalities providing complementary information could help improve early diagnosis of AD. In this paper, we propose a novel deep-learning-based framework to discriminate individuals with AD utilizing a multimodal and multiscale deep neural network. Our method delivers 82.4\% accuracy in identifying the individuals with mild cognitive impairment (MCI) who will convert to AD at 3 years prior to conversion (86.4\% combined accuracy for conversion within 1–3 years), a 94.23\% sensitivity in classifying individuals with clinical diagnosis of probable AD, and a 86.3\% specificity in classifying non-demented controls improving upon results in published literature.},
	language = {en},
	number = {1},
	urldate = {2024-04-04},
	journal = {Sci Rep},
	author = {Lu, Donghuan and Popuri, Karteek and Ding, Gavin Weiguang and Balachandar, Rakesh and Beg, Mirza Faisal and Alzheimer’s Disease Neuroimaging Initiative},
	month = apr,
	year = {2018},
	pages = {5697},
	file = {Lu et al. - 2018 - Multimodal and Multiscale Deep Neural Networks for.pdf:C\:\\Users\\sinad\\Zotero\\storage\\EL3L4EGH\\Lu et al. - 2018 - Multimodal and Multiscale Deep Neural Networks for.pdf:application/pdf},
}

@article{young_accurate_2013,
	title = {Accurate multimodal probabilistic prediction of conversion to {Alzheimer}'s disease in patients with mild cognitive impairment},
	volume = {2},
	issn = {22131582},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2213158213000600},
	doi = {10.1016/j.nicl.2013.05.004},
	abstract = {Accurately identifying the patients that have mild cognitive impairment (MCI) who will go on to develop Alzheimer's disease (AD) will become essential as new treatments will require identiﬁcation of AD patients at earlier stages in the disease process. Most previous work in this area has centred around the same automated techniques used to diagnose AD patients from healthy controls, by coupling high dimensional brain image data or other relevant biomarker data to modern machine learning techniques. Such studies can now distinguish between AD patients and controls as accurately as an experienced clinician. Models trained on patients with AD and control subjects can also distinguish between MCI patients that will convert to AD within a given timeframe (MCI-c) and those that remain stable (MCI-s), although differences between these groups are smaller and thus, the corresponding accuracy is lower. The most common type of classiﬁer used in these studies is the support vector machine, which gives categorical class decisions. In this paper, we introduce Gaussian process (GP) classiﬁcation to the problem. This fully Bayesian method produces naturally probabilistic predictions, which we show correlate well with the actual chances of converting to AD within 3 years in a population of 96 MCI-s and 47 MCI-c subjects. Furthermore, we show that GPs can integrate multimodal data (in this study volumetric MRI, FDG-PET, cerebrospinal ﬂuid, and APOE genotype with the classiﬁcation process through the use of a mixed kernel). The GP approach aids combination of different data sources by learning parameters automatically from training data via type-II maximum likelihood, which we compare to a more conventional method based on cross validation and an SVM classiﬁer. When the resulting probabilities from the GP are dichotomised to produce a binary classiﬁcation, the results for predicting MCI conversion based on the combination of all three types of data show a balanced accuracy of 74\%. This is a substantially higher accuracy than could be obtained using any individual modality or using a multikernel SVM, and is competitive with the highest accuracy yet achieved for predicting conversion within three years on the widely used ADNI dataset.},
	language = {en},
	urldate = {2024-04-04},
	journal = {NeuroImage: Clinical},
	author = {Young, Jonathan and Modat, Marc and Cardoso, Manuel J. and Mendelson, Alex and Cash, Dave and Ourselin, Sebastien},
	year = {2013},
	pages = {735--745},
	file = {Young et al. - 2013 - Accurate multimodal probabilistic prediction of co.pdf:C\:\\Users\\sinad\\Zotero\\storage\\D6UFUNBB\\Young et al. - 2013 - Accurate multimodal probabilistic prediction of co.pdf:application/pdf},
}

@article{desikan_genetic_2017,
	title = {Genetic assessment of age-associated {Alzheimer} disease risk: {Development} and validation of a polygenic hazard score},
	volume = {14},
	issn = {1549-1277},
	shorttitle = {Genetic assessment of age-associated {Alzheimer} disease risk},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5360219/},
	doi = {10.1371/journal.pmed.1002258},
	abstract = {Rahul Desikan and colleagues use genetic and epidemiological data from several large cohorts to derive a score for predicting the age-specific risk for developing Alzheimer's disease.},
	number = {3},
	urldate = {2024-05-01},
	journal = {PLoS Med},
	author = {Desikan, Rahul S.},
	month = mar,
	year = {2017},
	pmid = {28323831},
	pmcid = {PMC5360219},
	pages = {e1002258},
	file = {PubMed Central Full Text PDF:C\:\\Users\\sinad\\Zotero\\storage\\D9QE8PZ4\\Desikan et al. - 2017 - Genetic assessment of age-associated Alzheimer dis.pdf:application/pdf},
}

@misc{dosovitskiy_image_2021,
	title = {An {Image} is {Worth} 16x16 {Words}: {Transformers} for {Image} {Recognition} at {Scale}},
	shorttitle = {An {Image} is {Worth} 16x16 {Words}},
	url = {http://arxiv.org/abs/2010.11929},
	abstract = {While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer applied directly to sequences of image patches can perform very well on image classification tasks. When pre-trained on large amounts of data and transferred to multiple mid-sized or small image recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc.), Vision Transformer (ViT) attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.},
	language = {en},
	urldate = {2024-05-02},
	publisher = {arXiv},
	author = {Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
	month = jun,
	year = {2021},
	note = {arXiv:2010.11929 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
	file = {Dosovitskiy et al. - 2021 - An Image is Worth 16x16 Words Transformers for Im.pdf:C\:\\Users\\sinad\\Zotero\\storage\\GHRFQZRB\\Dosovitskiy et al. - 2021 - An Image is Worth 16x16 Words Transformers for Im.pdf:application/pdf},
}

@article{adarsh_multimodal_2024,
	title = {Multimodal classification of {Alzheimer}'s disease and mild cognitive impairment using custom {MKSCDDL} kernel over {CNN} with transparent decision-making for explainable diagnosis},
	volume = {14},
	copyright = {2024 The Author(s)},
	issn = {2045-2322},
	url = {https://www.nature.com/articles/s41598-024-52185-2},
	doi = {10.1038/s41598-024-52185-2},
	abstract = {The study presents an innovative diagnostic framework that synergises Convolutional Neural Networks (CNNs) with a Multi-feature Kernel Supervised within-class-similar Discriminative Dictionary Learning (MKSCDDL). This integrative methodology is designed to facilitate the precise classification of individuals into categories of Alzheimer's Disease, Mild Cognitive Impairment (MCI), and Cognitively Normal (CN) statuses while also discerning the nuanced phases within the MCI spectrum. Our approach is distinguished by its robustness and interpretability, offering clinicians an exceptionally transparent tool for diagnosis and therapeutic strategy formulation. We use scandent decision trees to deal with the unpredictability and complexity of neuroimaging data. Considering that different people's brain scans are different, this enables the model to make more detailed individualised assessments and explains how the algorithm illuminates the specific neuroanatomical regions that are indicative of cognitive impairment. This explanation is beneficial for clinicians because it gives them concrete ideas for early intervention and targeted care. The empirical review of our model shows that it makes diagnoses with a level of accuracy that is unmatched, with a classification efficacy of 98.27\%. This shows that the model is good at finding important parts of the brain that may be damaged by cognitive diseases.},
	language = {en},
	number = {1},
	urldate = {2024-06-04},
	journal = {Sci Rep},
	author = {Adarsh, V. and Gangadharan, G. R. and Fiore, Ugo and Zanetti, Paolo},
	month = jan,
	year = {2024},
	note = {Publisher: Nature Publishing Group},
	keywords = {Brain imaging, Magnetic resonance imaging},
	pages = {1774},
	file = {Full Text PDF:C\:\\Users\\sinad\\Zotero\\storage\\CVAVCEGG\\Adarsh et al. - 2024 - Multimodal classification of Alzheimer's disease a.pdf:application/pdf},
}

@article{wisely_convolutional_2022,
	title = {Convolutional neural network to identify symptomatic {Alzheimer}’s disease using multimodal retinal imaging},
	volume = {106},
	copyright = {© Author(s) (or their employer(s)) 2022. No commercial re-use. See rights and permissions. Published by BMJ.},
	issn = {0007-1161, 1468-2079},
	url = {https://bjo.bmj.com/content/106/3/388},
	doi = {10.1136/bjophthalmol-2020-317659},
	abstract = {Background/Aims To develop a convolutional neural network (CNN) to detect symptomatic Alzheimer’s disease (AD) using a combination of multimodal retinal images and patient data.
Methods Colour maps of ganglion cell-inner plexiform layer (GC-IPL) thickness, superficial capillary plexus (SCP) optical coherence tomography angiography (OCTA) images, and ultra-widefield (UWF) colour and fundus autofluorescence (FAF) scanning laser ophthalmoscopy images were captured in individuals with AD or healthy cognition. A CNN to predict AD diagnosis was developed using multimodal retinal images, OCT and OCTA quantitative data, and patient data.
Results 284 eyes of 159 subjects (222 eyes from 123 cognitively healthy subjects and 62 eyes from 36 subjects with AD) were used to develop the model. Area under the receiving operating characteristic curve (AUC) values for predicted probability of AD for the independent test set varied by input used: UWF colour AUC 0.450 (95\% CI 0.282, 0.592), OCTA SCP 0.582 (95\% CI 0.440, 0.724), UWF FAF 0.618 (95\% CI 0.462, 0.773), GC-IPL maps 0.809 (95\% CI 0.700, 0.919). A model incorporating all images, quantitative data and patient data (AUC 0.836 (CI 0.729, 0.943)) performed similarly to models only incorporating all images (AUC 0.829 (95\% CI 0.719, 0.939)). GC-IPL maps, quantitative data and patient data AUC 0.841 (95\% CI 0.739, 0.943).
Conclusion Our CNN used multimodal retinal images to successfully predict diagnosis of symptomatic AD in an independent test set. GC-IPL maps were the most useful single inputs for prediction. Models including only images performed similarly to models also including quantitative data and patient data.},
	language = {en},
	number = {3},
	urldate = {2024-06-04},
	journal = {British Journal of Ophthalmology},
	author = {Wisely, C. Ellis and Wang, Dong and Henao, Ricardo and Grewal, Dilraj S. and Thompson, Atalie C. and Robbins, Cason B. and Yoon, Stephen P. and Soundararajan, Srinath and Polascik, Bryce W. and Burke, James R. and Liu, Andy and Carin, Lawrence and Fekrat, Sharon},
	month = mar,
	year = {2022},
	pmid = {33243829},
	note = {Publisher: BMJ Publishing Group Ltd
Section: Clinical science},
	keywords = {diagnostic tests/investigation, imaging, retina},
	pages = {388--395},
	file = {Full Text PDF:C\:\\Users\\sinad\\Zotero\\storage\\YU6WX5FT\\Wisely et al. - 2022 - Convolutional neural network to identify symptomat.pdf:application/pdf},
}

@article{zhang_petmr_2017,
	title = {{PET}/{MR} {Imaging}: {New} {Frontier} in {Alzheimer}'s {Disease} and {Other} {Dementias}},
	volume = {10},
	issn = {1662-5099},
	shorttitle = {{PET}/{MR} {Imaging}},
	url = {https://www.frontiersin.org/articles/10.3389/fnmol.2017.00343},
	doi = {10.3389/fnmol.2017.00343},
	abstract = {Alzheimer's disease (AD) is the most common form of dementia; a progressive neurodegenerative disease that currently lacks an effective treatment option. Early and accurate diagnosis, in addition to quick elimination of differential diagnosis, allows us to provide timely treatments that delay the progression of AD. Imaging plays an important role for the early diagnosis of AD. The newly emerging PET/MR imaging strategies integrate the advantages of PET and MR to diagnose and monitor AD. This review introduces the development of PET/MR imaging systems, technical considerations of PET/MR imaging, special considerations of PET/MR in AD, and the system’s potential clinical applications and future perspectives in AD.},
	language = {English},
	urldate = {2024-06-04},
	journal = {Front. Mol. Neurosci.},
	author = {Zhang, Xin Y. and Yang, Zhen L. and Lu, Guang M. and Yang, Gui F. and Zhang, Long J.},
	month = nov,
	year = {2017},
	note = {Publisher: Frontiers},
	keywords = {Alzheimer diseases, clinical applications, PET radiotracers, PET/MR, technical considerations},
	file = {Full Text PDF:C\:\\Users\\sinad\\Zotero\\storage\\LZB5G3NU\\Zhang et al. - 2017 - PETMR Imaging New Frontier in Alzheimer's Diseas.pdf:application/pdf},
}

@article{chen_direct_2017,
	title = {Direct comparison of {PET}/{CT} and {MRI} to predict the pathological response to neoadjuvant chemotherapy in breast cancer: a meta-analysis},
	volume = {7},
	copyright = {2017 The Author(s)},
	issn = {2045-2322},
	shorttitle = {Direct comparison of {PET}/{CT} and {MRI} to predict the pathological response to neoadjuvant chemotherapy in breast cancer},
	url = {https://www.nature.com/articles/s41598-017-08852-8},
	doi = {10.1038/s41598-017-08852-8},
	abstract = {Both PET/CT and breast MRI are used to assess pathological complete response to neoadjuvant chemotherapy (NAC) in patients with breast cancer. The aim is to compare the utility of PET/CT and breast MRI by using head-to-head comparative studies. Literature databases were searched prior to July 2016. Eleven studies with a total of 527 patients were included. For PET/CT, the pooled SEN was 0.87 (95\% confidence interval (CI): 0.71–0.95) and SPE was 0.85 (95\% CI: 0.70–0.93). For MRI, the pooled SEN was 0.79 (95\% CI: 0.68–0.87) and SPE was 0.82 (95\% CI: 0.72–0.89). In the conventional contrast enhanced (CE)-MRI subgroup, PET/CT outperformed conventional CE-MRI with a higher pooled sensitivity (0.88 (95\% CI: 0.71, 0.95) vs. 0.74 (95\% CI: 0.60, 0.85), P = 0.018). In the early evaluation subgroup, PET/CT was superior to MRI with a notable higher pooled specificity (0.94 (95\% CI: 0.78, 0.98) vs. 0.83 (95\% CI: 0.81, 0.87), P = 0.015). The diagnostic performance of MRI is similar to that of PET/CT for the assessment of breast cancer response to NAC. However, PET/CT is more sensitive than conventional CE-MRI and more specific if the second imaging scan is performed before 3 cycles of NAC.},
	language = {en},
	number = {1},
	urldate = {2024-06-04},
	journal = {Sci Rep},
	author = {Chen, Lihua and Yang, Qifang and Bao, Jing and Liu, Daihong and Huang, Xuequan and Wang, Jian},
	month = aug,
	year = {2017},
	note = {Publisher: Nature Publishing Group},
	keywords = {Magnetic resonance imaging, Breast cancer},
	pages = {8479},
	file = {Full Text PDF:C\:\\Users\\sinad\\Zotero\\storage\\PMI3W96V\\Chen et al. - 2017 - Direct comparison of PETCT and MRI to predict the.pdf:application/pdf},
}

@misc{NationalInstituteOfAging_MildCognitiveImpairment_2024,
	title = {What {Is} {Mild} {Cognitive} {Impairment}? {\textbar} {Alzheimers}.gov},
	shorttitle = {What {Is} {Mild} {Cognitive} {Impairment}?},
	url = {http://www.nia.nih.gov/alzheimers-dementias/mild-cognitive-impairment},
	abstract = {Find information about mild cognitive impairment causes, signs and symptoms, diagnosis and treatment, and resources.},
	language = {en},
	urldate = {2024-09-05},
	file = {Snapshot:C\:\\Users\\sinad\\Zotero\\storage\\JDCYGBB6\\mild-cognitive-impairment.html:text/html},
}
@article{warren_functional_2023,
	title = {Functional magnetic resonance imaging, deep learning, and Alzheimer's disease: A systematic review},
	volume = {33},
	issn = {1051-2284},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10092597/},
	doi = {10.1111/jon.13063},
	shorttitle = {Functional magnetic resonance imaging, deep learning, and Alzheimer's disease},
	abstract = {Alzheimer's disease ({AD}) is currently diagnosed using a mixture of psychological tests and clinical observations. However, these diagnoses are not perfect, and additional diagnostic tools (e.g., {MRI}) can help improve our understanding of {AD} as well as our ability to detect the disease. Accordingly, a large amount of research has been invested into innovative diagnostic methods for {AD}. Functional {MRI} ({fMRI}) is a form of neuroimaging technology that has been used to diagnose {AD}; however, {fMRI} is incredibly noisy, complex, and thus lacks clinical use. Nonetheless, recent innovations in deep learning technology could enable the simplified and streamlined analysis of {fMRI}. Deep learning is a form of artificial intelligence that uses computer algorithms based on human neural networks to solve complex problems. For example, in {fMRI} research, deep learning models can automatically denoise images and classify {AD} by detecting patterns in participants’ brain scans. In this systematic review, we investigate how {fMRI} (specifically resting‐state {fMRI}) and deep learning methods are used to diagnose {AD}. In turn, we outline the common deep neural network, preprocessing, and classification methods used in the literature. We also discuss the accuracy, strengths, limitations, and future direction of {fMRI} deep learning methods. In turn, we aim to summarize the current field for new researchers, suggest specific areas for future research, and highlight the potential of {fMRI} to aid {AD} diagnoses.},
	pages = {5--18},
	number = {1},
	journaltitle = {Journal of Neuroimaging},
	shortjournal = {J Neuroimaging},
	author = {Warren, Samuel L. and Moustafa, Ahmed A.},
	urldate = {2024-09-11},
	date = {2023},
	pmid = {36257926},
	pmcid = {PMC10092597},
	file = {PubMed Central Full Text PDF:C\:\\Users\\sinad\\Zotero\\storage\\T8YEEGZB\\Warren and Moustafa - 2023 - Functional magnetic resonance imaging, deep learni.pdf:application/pdf},
}